## Put environment variables here.Dummy samples below##


OPENAI_API_KEY="XYX"
LLAMAPARSE_API_KEY=
AWS_REGION=
COHERE_API_KEY=

OTEL_EXPORTER_OTLP_HEADERS=
PHOENIX_COLLECTOR_ENDPOINT=
PHOENIX_API_KEY=
PG_HOST=localhost
PG_PORT=5432
PG_USER=
PG_PASSWORD=
PG_DATABASE=
PG_TABLE_NAME=
OLLAMA_HOST=
OLLAMA_PORT=
#===========
# Ollama LLM Configuration
OLLAMA_BASE_URL=
#OLLAMA_BASE_URL=
LLM_MODEL=

# Embedding Model Configuration

EMBEDDING_MODEL_NAME=
EMBEDDING_DIM=

# LlamaIndex/RAG Configuration

COLLECTION_NAME=
RETRIEVAL_TOP_K=10 
RERANKER_TOP_N=5  

# python -m phoenix.server.main serve  ( to start the phoenix)
# ollama pull all-minilm:l6-v2
# docker-compose up -d
# docker-compose down